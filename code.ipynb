{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "import gensim\r\n",
    "from gensim.utils import simple_preprocess\r\n",
    "from gensim.parsing.preprocessing import STOPWORDS\r\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\r\n",
    "from nltk.stem.porter import *\r\n",
    "import numpy as np\r\n",
    "from pprint import pprint\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.metrics import classification_report, accuracy_score\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marcd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\r\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['rec.autos', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\r\n",
    "train_dataset = fetch_20newsgroups(subset='train', categories=cats, shuffle=True)\r\n",
    "test_dataset = fetch_20newsgroups(subset='test', categories=cats, shuffle=True)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cats = list(train_dataset.target_names)\r\n",
    "\r\n",
    "# Create a dictionarry to associate the labels of the dataset with name of categories\r\n",
    "dict_cats = {'cars': [0], 'sport': [1, 2], 'science': [3, 4, 5, 6], 'religion': [7, 11], 'politics': [8, 9, 10]}\r\n",
    "\r\n",
    "# Create a dictionarry to associate the labels of the dataset with new numbers of categories\r\n",
    "dict_cats_number = {0: [0], 1: [1, 2], 2: [3, 4, 5, 6], 3: [7, 11], 4: [8, 9, 10]}\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize and lemmatize a text\r\n",
    "\r\n",
    "stemmer = SnowballStemmer('english')\r\n",
    "lemmatizer = WordNetLemmatizer()\r\n",
    "\r\n",
    "def stem_and_lemmatize(text):\r\n",
    "    lemm_text = lemmatizer.lemmatize(text, pos='v')\r\n",
    "    return stemmer.stem(lemm_text)\r\n",
    "\r\n",
    "def preprocess_data(text):\r\n",
    "    \"\"\"\r\n",
    "    This function returns the text preprocessed: a new text with the words stemmed and lemmatized, without the stop words and the words shorter than 3 letters.\r\n",
    "    \"\"\"\r\n",
    "    words = []\r\n",
    "    text = simple_preprocess(text) #the text is converted into a list of lower-case words\r\n",
    "    for token in text:\r\n",
    "        if token not in STOPWORDS and len(token) > 3:\r\n",
    "            words.append(stem_and_lemmatize(token))\r\n",
    "    return ' '.join(words)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(train_dataset, test_dataset):\r\n",
    "    \"\"\"\r\n",
    "    This function preprocess the dataset.\r\n",
    "    It returns:\r\n",
    "        The Tfidf vectors of training and testing datasets (X_train, X_test)\r\n",
    "        The labels (y_train, y_test)\r\n",
    "        The Tfidf vectorizer object\r\n",
    "    \"\"\"\r\n",
    "    train_processed_texts = []\r\n",
    "    for text in train_dataset.data:\r\n",
    "        train_processed_texts.append(preprocess_data(text))\r\n",
    "    test_processed_texts = []\r\n",
    "    for text in test_dataset.data:\r\n",
    "        test_processed_texts.append(preprocess_data(text))\r\n",
    "\r\n",
    "    vect = TfidfVectorizer(stop_words='english', min_df=2)\r\n",
    "    X_train = vect.fit_transform(train_processed_texts)\r\n",
    "    X_test = vect.transform(test_processed_texts)\r\n",
    "    y_train = np.array(train_dataset.target)\r\n",
    "    y_test = np.array(test_dataset.target)\r\n",
    "\r\n",
    "    return X_train, X_test, y_train, y_test, vect\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, vect = preprocess_dataset(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier: we choose a SVM\r\n",
    "\r\n",
    "# First, let transform our labels into the labels for the category we chose.\r\n",
    "def transform_label(labels):\r\n",
    "    labels2 = [0 for k in range(len(labels))]\r\n",
    "    for i in range(len(labels)):\r\n",
    "        label = labels[i]\r\n",
    "        for j in range(5):\r\n",
    "            if label in dict_cats_number[j]:\r\n",
    "                labels2[i] = j\r\n",
    "                break\r\n",
    "    return labels2\r\n",
    "\r\n",
    "def trained_svm(X_train, y_train, kernel):\r\n",
    "    model = svm.SVC(kernel=kernel, gamma='auto')\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    return model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training done.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86       396\n",
      "           1       0.98      1.00      0.99      4074\n",
      "\n",
      "    accuracy                           0.98      4470\n",
      "   macro avg       0.99      0.88      0.92      4470\n",
      "weighted avg       0.98      0.98      0.98      4470\n",
      "\n",
      "Accuracy:  0.9782997762863535\n"
     ]
    }
   ],
   "source": [
    "# Performance of our classifier\r\n",
    "y_train = transform_label(y_train)\r\n",
    "y_test = transform_label(y_test)\r\n",
    "\r\n",
    "print(\"Training...\")\r\n",
    "kernel = 'linear'\r\n",
    "SVM = trained_svm(X_train, y_train, kernel)\r\n",
    "print(\"Training done.\")\r\n",
    "\r\n",
    "y_pred = SVM.predict(X_test)\r\n",
    "report = classification_report(y_test, y_pred)\r\n",
    "accuracy = accuracy_score(y_test, y_pred)\r\n",
    "\r\n",
    "print(report)\r\n",
    "print(\"Accuracy: \", accuracy)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The article clasifier\r\n",
    "\r\n",
    "# First, let's create the profiles and their fields of interest.\r\n",
    "\r\n",
    "profiles = {\r\n",
    "    'Thomas' : ['sport', 'politics'],\r\n",
    "    'Aline' : ['cars'],\r\n",
    "    'George' : ['religion', 'cars'],\r\n",
    "    'Eva' : ['science', 'politics'],\r\n",
    "    'Lorenzo' : ['sport']\r\n",
    "}\r\n",
    "\r\n",
    "profiles_number = {}\r\n",
    "for key in profiles.keys():\r\n",
    "    interests = profiles[key]\r\n",
    "    interests_number = []\r\n",
    "    for interest in interests:\r\n",
    "        cats = dict_cats[interest]\r\n",
    "        cats = transform_label(cats)\r\n",
    "        for cat in cats:\r\n",
    "            interests_number.append(cat)\r\n",
    "    profiles_number[key] = interests_number\r\n",
    "\r\n",
    "\r\n",
    "def predict_text(text):\r\n",
    "    \"\"\"\r\n",
    "    This function returns the predicted category of an input text.\r\n",
    "    \"\"\"\r\n",
    "    text = [preprocess_data(text)]\r\n",
    "    text = vect.transform(text)\r\n",
    "    prediction = SVM.predict(text)[0]\r\n",
    "    cat = list(dict_cats.keys())[prediction]\r\n",
    "    return cat\r\n",
    "\r\n",
    "\r\n",
    "def main():\r\n",
    "        text = input(\"Please type the text you want and press enter: \")\r\n",
    "        print(\"Processing...\")\r\n",
    "        category = predict_text(text)\r\n",
    "        users = []\r\n",
    "        for user in profiles.keys():\r\n",
    "            if category in profiles[user]:\r\n",
    "                users.append(user)\r\n",
    "        print(\"The theme of this text is: \", category)\r\n",
    "        print('')\r\n",
    "        print(\"So, this text will be sent to the following users:\")\r\n",
    "        for user in users:\r\n",
    "            print(\"     -  \", user)\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "The theme of this text is:  science\n",
      "\n",
      "So, this text will be sent to the following users:\n",
      "     -   Eva\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\r\n",
    "Run this cell to try the programm.\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (conda)",
   "name": "python379jvsc74a57bd08c582ba49a6c065c1b2a573e9441c53c7402ec5eb3ada4b88a416f96448db9c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}